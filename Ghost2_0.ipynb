{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVaAeTx0uMrB"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSS3f3aO-4Ta"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "%cd /content\n",
        "\n",
        "! git clone --recurse-submodules https://github.com/jagrut-thakare/ghost-2.0\n",
        "%cd ghost-2.0\n",
        "! git submodule init\n",
        "! git submodule update\n",
        "os.makedirs(\"aligner_checkpoints\", exist_ok=True)\n",
        "os.makedirs(\"blender_checkpoints\", exist_ok=True)\n",
        "os.makedirs(\"src/losses/gaze_models\", exist_ok=True)\n",
        "os.makedirs(\"weights\", exist_ok=True)\n",
        "\n",
        "! wget -O aligner_checkpoints/aligner_1020_gaze_final.ckpt https://github.com/ai-forever/ghost-2.0/releases/download/aligner/aligner_1020_gaze_final.ckpt\n",
        "! wget -O blender_checkpoints/blender_lama.ckpt https://github.com/ai-forever/ghost-2.0/releases/download/aligner/blender_lama.ckpt\n",
        "! wget -O weights/backbone50_1.pth https://github.com/ai-forever/ghost-2.0/releases/download/aligner/backbone50_1.pth\n",
        "! wget -O weights/vgg19-d01eb7cb.pth https://github.com/ai-forever/ghost-2.0/releases/download/aligner/vgg19-d01eb7cb.pth\n",
        "! wget -O weights/segformer_B5_ce.onnx https://github.com/ai-forever/ghost-2.0/releases/download/aligner/segformer_B5_ce.onnx\n",
        "! wget -O gaze_models.zip https://github.com/ai-forever/ghost-2.0/releases/download/aligner/gaze_models.zip\n",
        "\n",
        "with zipfile.ZipFile(\"gaze_models.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"src/losses/\")\n",
        "\n",
        "os.remove(\"gaze_models.zip\")\n",
        "print(\"✅ All models downloaded and extracted successfully.\")\n",
        "\n",
        "! mkdir repos\n",
        "\n",
        "%cd repos\n",
        "\n",
        "! git clone --recurse-submodules https://github.com/yfeng95/DECA\n",
        "%cd DECA\n",
        "! git submodule init\n",
        "! git submodule update\n",
        "%cd ..\n",
        "\n",
        "! git clone --recurse-submodules https://github.com/jagrut-thakare/emoca\n",
        "%cd emoca\n",
        "\n",
        "! git submodule init\n",
        "! git submodule update\n",
        "\n",
        "os.makedirs(\"gdl_apps/EmotionRecognition\", exist_ok=True)\n",
        "os.makedirs(\"assets/EmotionRecognition/image_based_networks\", exist_ok=True)\n",
        "\n",
        "!wget -O ResNet50.zip https://github.com/anastasia-yaschenko/emoca/releases/download/resnet/ResNet50.zip\n",
        "\n",
        "with zipfile.ZipFile(\"ResNet50.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"gdl_apps/EmotionRecognition\")\n",
        "    zip_ref.extractall(\"assets/EmotionRecognition/image_based_networks\")\n",
        "\n",
        "os.remove(\"ResNet50.zip\")\n",
        "\n",
        "print(\"✅ ResNet checkpoints downloaded, unpacked, and ZIP removed.\")\n",
        "%cd ..\n",
        "\n",
        "! git clone --recurse-submodules https://github.com/anastasia-yaschenko/BlazeFace_PyTorch\n",
        "\n",
        "%cd BlazeFace_PyTorch\n",
        "! git submodule init\n",
        "! git submodule update\n",
        "%cd ..\n",
        "\n",
        "! git clone --recurse-submodules https://github.com/chroneus/stylematte\n",
        "\n",
        "%cd stylematte\n",
        "\n",
        "! git submodule init\n",
        "! git submodule update\n",
        "\n",
        "os.makedirs(\"stylematte/checkpoints\", exist_ok=True)\n",
        "os.makedirs(\"stylegan3\", exist_ok=True)\n",
        "\n",
        "!wget -O stylematte/checkpoints/stylematte_pure.pth https://github.com/chroneus/stylematte/releases/download/weights/stylematte_pure.pth\n",
        "!wget -O stylematte/checkpoints/stylematte_synth.pth https://github.com/chroneus/stylematte/releases/download/weights/stylematte_synth.pth\n",
        "!wget -O stylegan3/animals.pkl https://github.com/chroneus/stylematte/releases/download/weights/animals.pkl\n",
        "!wget -O stylegan3/humans.pkl https://github.com/chroneus/stylematte/releases/download/weights/humans.pkl\n",
        "%cd ..\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Fs576UU49E",
        "outputId": "1c77c5ee-f954-4a2d-b498-d763d64cc594"
      },
      "outputs": [],
      "source": [
        "! conda config --add channels conda-forge\n",
        "! conda config --set channel_priority strict\n",
        "! conda create -n ghost python=3.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Lw3AzzOqQL",
        "outputId": "e458f9a9-bb08-48db-ac0a-326c0b313382"
      },
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNz05y2ZOoyo",
        "outputId": "46da2088-9c6b-4925-cbb7-115c7188813b"
      },
      "outputs": [],
      "source": [
        "! conda install -c pytorch3d-nightly pytorch3d\n",
        "! pip install face-alignment==1.3.5 facenet-pytorch==2.5.2 -U git+https://github.com/facebookresearch/fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5W7FHu0oeLz",
        "outputId": "95486f59-47be-4522-b342-1d020ba13252"
      },
      "outputs": [],
      "source": [
        "! conda install scikit-image -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e02a064e"
      },
      "outputs": [],
      "source": [
        "! conda install -c conda-forge imgaug -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0afb8ccd"
      },
      "outputs": [],
      "source": [
        "! conda install numpy==1.23.5 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "069oaBBtd5ye"
      },
      "outputs": [],
      "source": [
        "! conda install tensorboardX tensorboard -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ000ksGuFAB"
      },
      "source": [
        "# DECA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "DGYmnv-UzFvd",
        "outputId": "837e4676-37ac-4e53-a4f3-1ad35b70e730"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1rp8kdyLPvErw2dTmqtjISRVvQLj6Yzje\"\n",
        "destination = \"/content/ghost-2.0/repos/DECA/data/deca_model.tar\"\n",
        "\n",
        "gdown.download(id=file_id, output=destination, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND3x8X3OuElb",
        "outputId": "ae5ac58f-ee14-4957-d653-02729fa98f93"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Create data directory\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Set FLAME credentials (assumed to be already set)\n",
        "username = userdata.get('DECA')\n",
        "password = userdata.get('DECA_Password')\n",
        "\n",
        "# Check if credentials are provided\n",
        "if not username or not password:\n",
        "    raise ValueError(\"Environment variables  must be set.\")\n",
        "\n",
        "# Encode username and password for URL\n",
        "import urllib.parse\n",
        "username_enc = urllib.parse.quote_plus(username)\n",
        "password_enc = urllib.parse.quote_plus(password)\n",
        "\n",
        "# Create the download command\n",
        "download_url = f\"https://download.is.tue.mpg.de/download.php?domain=flame&sfile=FLAME2020.zip&resume=1\"\n",
        "post_data = f\"username={username_enc}&password={password_enc}\"\n",
        "\n",
        "# Use wget with POST data\n",
        "!wget --post-data=\"{post_data}\" \"{download_url}\" -O DECA.zip --no-check-certificate --continue\n",
        "\n",
        "# Unzip and move model file\n",
        "!unzip DECA.zip -d ./temp\n",
        "!mv ./temp/* /content/ghost-2.0/repos/DECA/data/\n",
        "!rm -rf ./temp/\n",
        "!rm -rf DECA.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q6IZINTuIkd"
      },
      "source": [
        "# EMOCA ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVrvt_Pj5YFN",
        "outputId": "2421fdbb-e0fa-4709-90de-00ba92f0603d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(\"/ps/scratch/rdanecek/FaceRecognition/\", exist_ok=True)\n",
        "# Google Drive file ID\n",
        "file_id = \"1gSUm_sZFOjcHij4wBptI3CEvmWQzVHoS\"\n",
        "output_path = \"/ps/scratch/rdanecek/FaceRecognition/resnet50_ft_weight.pkl\"\n",
        "\n",
        "# Remove the file if it exists before downloading\n",
        "if os.path.exists(output_path):\n",
        "    os.remove(output_path)\n",
        "    print(f\"Removed existing file: {output_path}\")\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
        "print(f\"Downloaded file to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"agg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "SWIN not found, will not be able to use SWIN models\n",
            "Could not import EmoSwinModule. SWIN models will not be available.  Make sure you pull the repository with submodules to enable Swin.\n",
            "Could not import EmoNetModule. EmoNet models will not be available.  Make sure you pull the repository with submodules to enable EmoNet.\n",
            "Looking for checkpoint in 'repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints'\n",
            "Found 1 checkpoints\n",
            " - repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt\n",
            "Selecting checkpoint 'repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt'\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.4.9 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt`\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "creating the FLAME Decoder\n",
            "trained model found. load ./repos/DECA/data/deca_model.tar\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/pytorch3d/io/obj_io.py:550: UserWarning: Mtl file does not exist: ./repos/DECA/data/template.mtl\n",
            "  warnings.warn(f\"Mtl file does not exist: {f}\")\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jagrut.thakare/Project/ghost-2.0/inference.py\", line 173, in <module>\n",
            "    main(args)\n",
            "  File \"/home/jagrut.thakare/Project/ghost-2.0/inference.py\", line 33, in main\n",
            "    aligner.cuda()\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py\", line 76, in cuda\n",
            "    return super().cuda(device=device)\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1053, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 2 more times]\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 930, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1053, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 47.81 MiB is free. Process 8786 has 13.66 GiB memory in use. Including non-PyTorch memory, this process has 1.79 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 10.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "! python inference.py --source ./examples/images/elon.jpg --target ./examples/images/hab.jpg --save_path result1.png --ckpt_a ./temp/aligner.ckpt --ckpt_b ./temp/blender.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18P20z7nVOwq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2EnLqR-u20z"
      },
      "outputs": [],
      "source": [
        "! conda run -n ghost python v2h5.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WQEU5evrLUB"
      },
      "outputs": [],
      "source": [
        "! conda run -n ghost pip install numpy==1.23 h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wr7L6JSxVRKE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SWIN not found, will not be able to use SWIN models\n",
            "Could not import EmoSwinModule. SWIN models will not be available.  Make sure you pull the repository with submodules to enable Swin.\n",
            "Could not import EmoNetModule. EmoNet models will not be available.  Make sure you pull the repository with submodules to enable EmoNet.\n",
            "Looking for checkpoint in 'repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints'\n",
            "Found 1 checkpoints\n",
            " - repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt\n",
            "Selecting checkpoint 'repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt'\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.4.9 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint repos/emoca/assets/EmotionRecognition/image_based_networks/ResNet50/checkpoints/deca-epoch=01-val_loss_total/dataloader_idx_0=1.27607644.ckpt`\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "creating the FLAME Decoder\n",
            "trained model found. load ./repos/DECA/data/deca_model.tar\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/pytorch3d/io/obj_io.py:550: UserWarning: Mtl file does not exist: ./repos/DECA/data/template.mtl\n",
            "  warnings.warn(f\"Mtl file does not exist: {f}\")\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jagrut.thakare/Project/ghost-2.0/train_aligner.py\", line 413, in <module>\n",
            "    train_dataloader = create_dataset(cfg.train_options, train_transform=train_transform, flip_transform=True, cross=False)\n",
            "  File \"/home/jagrut.thakare/Project/ghost-2.0/train_aligner.py\", line 389, in create_dataset\n",
            "    dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=cfg.shuffle, num_workers=cfg.num_workers)\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 383, in __init__\n",
            "    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n",
            "  File \"/home/jagrut.thakare/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/utils/data/sampler.py\", line 165, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: num_samples should be a positive integer value, but got num_samples=0\n"
          ]
        }
      ],
      "source": [
        "! python train_aligner.py --config ./configs/aligner.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! python train_blender.py --config ./configs/blender.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PVaAeTx0uMrB",
        "nJ000ksGuFAB",
        "3Q6IZINTuIkd",
        "18P20z7nVOwq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ghost",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
